{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "from source.DataFrameSelector import DataFrameSelector\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from source.ML import HelperFunction\n",
    "from source.ML import Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"..\", \"data\")\n",
    "\n",
    "def load_csv(filename, path=DATA_PATH):\n",
    "    return pd.read_csv(os.path.join(path, filename))\n",
    "\n",
    "def to_utc_datetime(df, column=\"time\"):\n",
    "    df[column] = df.apply(lambda row: datetime.strptime(row[column], \"%Y-%m-%d\").astimezone(timezone.utc), axis=1)\n",
    "    return df\n",
    "\n",
    "def get_price():\n",
    "    e_data = load_csv(\"energy_dataset.csv\")\n",
    "    return e_data[[\"time\", \"price day ahead\", \"total load actual\", \"price\"]].rename(\n",
    "        columns={\"price day ahead\": \"TSO_price_forecast\",\n",
    "                 \"total load actual\": \"load\"})\n",
    "\n",
    "def add_weather_data(df):\n",
    "    w_data = load_csv(\"weather_features.csv\").drop(columns=[\"weather_id\", \"weather_icon\", \"temp_min\", \"temp_max\"])\n",
    "    w_data = w_data.join(other=df.set_index(\"time\"), on=\"time\").drop_duplicates(subset=[\"time\", \"city_name\"])\n",
    "    return w_data.reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = load_csv(\"train_1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "page_details = data.Page.str.extract(r'(?P<topic>.*)\\_(?P<lang>.*).wikipedia.org\\_(?P<access>.*)\\_(?P<type>.*)')\n",
    "data = pd.concat([page_details, data], axis=1)\n",
    "data.drop(columns=\"Page\", inplace=True)\n",
    "data.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "foo = data.iloc[[21546]].copy(deep=True).drop(columns=[\"topic\", \"lang\", \"access\", \"type\"]).reset_index(drop=True)\n",
    "foo = foo.T.reset_index().rename(columns={\"index\": \"time\", 0: \"value\"})\n",
    "foo[\"time\"] = pd.to_datetime(foo[\"time\"])\n",
    "foo.set_index(\"time\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "target_column = \"value\"\n",
    "#features = [\"temp\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_deg\", \"rain_1h\", \"rain_3h\", \"snow_3h\", \"clouds_all\", \"load\", \"price\"]\n",
    "features = [\"value\"]\n",
    "num_features = len(features)\n",
    "foo = foo.loc[:, features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "index_threshold = 500\n",
    "\n",
    "train_data = foo.iloc[:index_threshold]\n",
    "test_data = foo.iloc[index_threshold:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(train_data[target_column].values.reshape(-1, 1))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#train_data_scaled = torch.FloatTensor(train_data_scaled).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def create_input_output_sequence(input_data, seq_len, pred_len=1, multivar=False):\n",
    "    '''\n",
    "    Takes a TimeSeries and creates new data points, where each data point is a sequence of timesteps from the TimeSeries\n",
    "    :param input_data: TimeSeries-Data from which so create sequences,\n",
    "    where each row is one Timestep\n",
    "    and each column is one Feature\n",
    "    :param seq_len: Length of the sequence, i.e. the number of timesteps from the input_data for each input\n",
    "    :param pred_len: Length of the prediction, i.e. the number of timesteps from the input_data which are prediction by the input\n",
    "    :param multivar: bool; if false only takes the last column as features for the prediction\n",
    "    :return: Returns two FloatTensors X, y\n",
    "    X contains sequences of shape [seq_len, input_data.number_of_columns]\n",
    "    y contains sequences of shape [pred_len, 1] if multivar=False, [pred_len, input_data.number_of_columns] otherwise\n",
    "    '''\n",
    "    # if multivar: target column has to be the last column\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(input_data) - seq_len - pred_len + 1):\n",
    "        train_seq = input_data[i:i+seq_len]\n",
    "        train_label = input_data[i+seq_len:i+seq_len+pred_len]\n",
    "        if not multivar:\n",
    "            train_label = train_label[:, -1]\n",
    "        X.append(train_seq)\n",
    "        y.append(train_label)\n",
    "    X=torch.FloatTensor(X).to(device)\n",
    "    y=torch.FloatTensor(y).to(device)\n",
    "    return X, y\n",
    "\n",
    "seq_len = 24 #24*7\n",
    "out_seq_len = 5\n",
    "X, y = HelperFunction.create_input_output_sequence(train_data_scaled, seq_len, out_seq_len)\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# x has values from a to b, y has values from b+1 to c, so x+y should be equal to the a-c sclice of train_data_scaled\n",
    "assert np.sum(np.concatenate((X.cpu().numpy()[0].flatten(), y.cpu().numpy()[0].flatten()))\n",
    "              - torch.FloatTensor(train_data_scaled[0:seq_len+out_seq_len].flatten()).numpy()) == 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def split_validation(X, y, num_val):\n",
    "    idx = np.random.choice(X.shape[0], num_val, replace=False)\n",
    "    mask = np.ones(X.shape[0], bool)\n",
    "    mask[idx] = False\n",
    "    return X[mask], y[mask], X[idx], y[idx]\n",
    "\n",
    "X, y, X_val, y_val = HelperFunction.split_validation(X, y, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([476, 24, 1])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class D_LSTM_Seq(nn.Module):\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        super(D_LSTM_Seq, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.lstm_in = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.lstm_repeat = nn.LSTM(hidden_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        # self.lstm_repeat = nn.LSTM(1, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        return (torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(device),\n",
    "                torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(device))\n",
    "\n",
    "    def lstm_wrapper(self, batch):\n",
    "        _, (x, _) = self.lstm_repeat(batch, self.init_hidden_cell(batch.shape[0]))\n",
    "        return x[-1] # last layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x, (_, _) = self.lstm_in(x, self.init_hidden_cell(batch_size))\n",
    "        # x.shape = [batch, seq_len, hidden_dim] = [batch, timesteps t, h(t)]\n",
    "        x = x.unsqueeze(1).repeat(1, self.out_seq_len, 1, 1)\n",
    "        # x.shape = [batch, out_seq_len repeats of batch, seq_len, hiddem_dim]\n",
    "        # so we can get batch_size batches instead of out_seq_len sized ones\n",
    "        x = x.view(self.out_seq_len, batch_size, -1, self.hidden_dim)\n",
    "        # x.shape = [out_seq_len repeats of batch, batch, seq_len, hiddem_dim]\n",
    "        x = torch.cat([self.lstm_wrapper(batch) for batch in x])\n",
    "        # x.shape = [batch * out_seq_len, hidden_dim]\n",
    "        x = self.linear(x)\n",
    "        # x.shape = [batch * out_seq_len, output_dim]\n",
    "        # order output back into out_seq_len size\n",
    "        x = x.view(batch_size, self.out_seq_len, -1)\n",
    "        if x.shape[-1] == 1:\n",
    "            x = x.view(x.shape[0], -1) # if output_dim = 1, merge last two dimensions\n",
    "        return x\n",
    "\n",
    "class LSTMSimple(nn.Module):\n",
    "    '''\n",
    "    Simple LSTM network, which can only predict 1 value\n",
    "    Input is given to a LSTM, output of the LSTM is the input for a LinearLayer\n",
    "    Output of the LinearLayer is the prediction\n",
    "    '''\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        super(LSTMSimple, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (x, _) = self.lstm(x) # x.shape = [lstm_layer, batch, hidden_dim]\n",
    "        x = x[-1] # last lstm_layer; x.shape = [batch, hidden_dim]\n",
    "        x = self.linear(x) # x.shape = [batch, output_dim]\n",
    "        return x\n",
    "\n",
    "class LSTMSeq2SeqOle(nn.Module):\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        '''\n",
    "        LSTM network to predict multiple values\n",
    "        Uses one LSTM to create a vector-representation of the input sequence, then creates a new sequence with\n",
    "        that vector as feature for every timestep as input for a second LSTM;\n",
    "        Output of the second LSTM at each timestep is given to a LinearLayer\n",
    "        Output of the LinearLayer is the prediction\n",
    "        :param input_dim: Number of features for each timestep in the sequence used as the input\n",
    "        :param out_seq_len: Number of predicions\n",
    "        :param hidden_dim:\n",
    "        :param layer_dim:\n",
    "        :param output_dim: Number of features for each prediction\n",
    "        '''\n",
    "        super(LSTMSeq2SeqOle, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.lstm_in = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.lstm_repeat = nn.LSTM(hidden_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input is encoded by lstm_in\n",
    "        Output of lstm_in is the input of lstm_repeat; lstm_repeat starts with new empty states (h,c)\n",
    "        Output of lstm_in is repeated out_seq_len times to get out_seq_len long sequences\n",
    "        \"\"\"\n",
    "        # encode\n",
    "        _, (x, _) = self.lstm_in(x) # x.shape = [lstm_layer, batch, hidden_dim]\n",
    "        x = x[-1] # last lstm_layer; x.shape = [batch, hidden_dim]\n",
    "        x = x.unsqueeze(1).repeat(1, self.out_seq_len, 1) # x.shape = [batch, out_seq_len, hiddem_dim]\n",
    "\n",
    "        # decode\n",
    "        x, (_, _) = self.lstm_repeat(x) # x.shape = [batch, out_seq_len, hidden_dim]\n",
    "        x = self.linear(x) # x.shape = [batch, out_seq_len, output_dim]\n",
    "        if x.shape[-1] == 1:\n",
    "            x = x.view(x.shape[0], -1) # if output_dim = 1, merge last two dimensions\n",
    "        return x\n",
    "\n",
    "class LSTMSeq2SeqBook(nn.Module):\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        '''\n",
    "        LSTM network to predict multiple values\n",
    "        Uses one LSTM to process the input and uses the final cell/hidden-state as seed for a second LSTM,\n",
    "        then creates a new sequence with zero-vector as feature for every timestep as input for the second LSTM;\n",
    "        Output of the second LSTM at each timestep is given to a LinearLayer\n",
    "        Output of the LinearLayer is the prediction\n",
    "        :param input_dim: Number of features for each timestep in the sequence used as the input\n",
    "        :param out_seq_len: Number of predicions\n",
    "        :param hidden_dim:\n",
    "        :param layer_dim:\n",
    "        :param output_dim: Number of features for each prediction\n",
    "        '''\n",
    "        super(LSTMSeq2SeqBook, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.lstm_in = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.lstm_repeat = nn.LSTM(1, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input is encoded by lstm_in\n",
    "        Output of lstm_in is the starting state for lstm_repeat (h, c)\n",
    "        Input for lstm_repeat is zero ([batch, out_seq_len, 1])\n",
    "        \"\"\"\n",
    "        # encode\n",
    "        _, (h, c) = self.lstm_in(x)\n",
    "        # decode\n",
    "        x, (_, _) = self.lstm_repeat(torch.zeros(x.shape[0], self.out_seq_len, 1).to(device), (h, c)) # x.shape = [batch, out_seq_len, hidden_dim]\n",
    "        x = self.linear(x) # x.shape = [batch, out_seq_len, output_dim]\n",
    "        if x.shape[-1] == 1:\n",
    "            x = x.view(x.shape[0], -1) # if output_dim = 1, merge last two dimensions\n",
    "        return x\n",
    "\n",
    "class LSTMSeq2SeqBookTranslation(nn.Module):\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        '''\n",
    "        LSTM network to predict multiple values\n",
    "        Uses one LSTM to process the input and uses the final cell/hidden-state as seed for a second LSTM,\n",
    "        then creates a new sequence where the feature of timestep x is the output of the network at timestep x-1;\n",
    "        Output of the second LSTM at each timestep is given to a LinearLayer\n",
    "        Output of the LinearLayer is the prediction\n",
    "        The forward function requires the correct labels as additional parameter during training\n",
    "        :param input_dim: Number of features for each timestep in the sequence used as the input\n",
    "        :param out_seq_len: Number of predicions\n",
    "        :param hidden_dim:\n",
    "        :param layer_dim:\n",
    "        :param output_dim: Number of features for each prediction\n",
    "        '''\n",
    "        super(LSTMSeq2SeqBookTranslation, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.lstm_in = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.lstm_repeat = nn.LSTM(1, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        \"\"\"\n",
    "        During training y must be the correct labels. After training y must be None\n",
    "        Input is encoded by lstm_in\n",
    "        Output of lstm_in is the starting state for lstm_repeat (h, c)\n",
    "        Input for lstm_repeat during training:\n",
    "            the labels shifted by one (timestep x gets the correct value of timestep x-1)\n",
    "            last label is discarded, first label is zero\n",
    "        Input for lstm_repeat after training:\n",
    "            Output of lstm_repeat at timestep x-1 is the input for timestep x\n",
    "            in this case: output is a vector but input must be len 1, thus the output at timestep x-1 is used for a linear layer first\n",
    "        \"\"\"\n",
    "        # encode\n",
    "        _, (h, c) = self.lstm_in(x)\n",
    "        # decode\n",
    "        if y is not None:\n",
    "            decoder_input = y.unsqueeze(-1).roll(1, dims=1)\n",
    "            decoder_input[:, 0] = 0\n",
    "            x, (_, _) = self.lstm_repeat(decoder_input, (h, c))\n",
    "            x = self.linear(x)\n",
    "        else:\n",
    "            # seq_len per input must be 1 since we feed the seq manually\n",
    "            # feature is the output of the last iteration, zero for first\n",
    "            decoder_input = torch.zeros(x.shape[0], 1, 1).to(device)\n",
    "            # out_seq_len, batch, output\n",
    "            x = torch.zeros(self.out_seq_len, x.shape[0], 1).to(device)\n",
    "            for i in range(self.out_seq_len):\n",
    "                _, (h, c) = self.lstm_repeat(decoder_input, (h, c))\n",
    "                x[i] = self.linear(h[-1]) # h[-1] = last layer\n",
    "                decoder_input = x[i].unsqueeze(1) # unsqueeze to add seq_len 1\n",
    "            # x.shape = [out_seq_len, batch, 1]\n",
    "            x = x.transpose(0, 1) # batch first\n",
    "        # x.shape = [batch, out_seq_len, output_dim]\n",
    "        if x.shape[-1] == 1:\n",
    "            x = x.view(x.shape[0], -1) # if output_dim = 1, merge last two dimensions\n",
    "        return x\n",
    "\n",
    "class LSTMSeq2SeqDistribution(nn.Module):\n",
    "    def __init__(self, input_dim, out_seq_len=1, hidden_dim=100, layer_dim=1, output_dim=1):\n",
    "        '''\n",
    "        LSTM network to predict multiple values\n",
    "        Uses one LSTM to learn a normal distribution, then creates a new sequence with samples from the distribution\n",
    "        as feature for every timestep as input for the second LSTM;\n",
    "        Output of the second LSTM at each timestep is given to a LinearLayer\n",
    "        Output of the LinearLayer is the prediction\n",
    "        :param input_dim: Number of features for each timestep in the sequence used as the input\n",
    "        :param out_seq_len: Number of predicions\n",
    "        :param hidden_dim:\n",
    "        :param layer_dim:\n",
    "        :param output_dim: Number of features for each prediction\n",
    "        '''\n",
    "        super(LSTMSeq2SeqDistribution, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.lstm_in = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear_mu = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear_log_std = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lstm_repeat = nn.LSTM(hidden_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear_output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input is encoded by lstm_in\n",
    "        Output of lstm_in is the input of lstm_repeat; lstm_repeat starts with new empty states (h,c)\n",
    "        Output of lstm_in is repeated out_seq_len times to get out_seq_len long sequences\n",
    "        \"\"\"\n",
    "        # https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73\n",
    "        # encode\n",
    "        _, (x, _) = self.lstm_in(x) # x.shape = [lstm_layer, batch, hidden_dim]\n",
    "        x = x[-1] # last lstm_layer; x.shape = [batch, hidden_dim]\n",
    "        mu = self.linear_mu(x) # mu.shape = [batch, hidden_dim]\n",
    "        log_std = self.linear_log_std(x) # log_std.shape = [batch, hidden_dim]\n",
    "        dist = Normal(mu, torch.exp(torch.clamp(log_std, -8, 8)))\n",
    "        x = dist.rsample() # x.shape = [batch, hidden_dim]\n",
    "        x = x.unsqueeze(1).repeat(1, self.out_seq_len, 1) # x.shape = [batch, out_seq_len, hiddem_dim]\n",
    "        # decode\n",
    "        x, (_, _) = self.lstm_repeat(x) # x.shape = [batch, out_seq_len, hidden_dim]\n",
    "        x = self.linear_output(x) # x.shape = [batch, out_seq_len, output_dim]\n",
    "        if x.shape[-1] == 1:\n",
    "            x = x.view(x.shape[0], -1) # if output_dim = 1, merge last two dimensions\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "LSTMSeq2SeqOle(\n  (lstm_in): LSTM(1, 64, batch_first=True)\n  (lstm_repeat): LSTM(64, 64, batch_first=True)\n  (linear): Linear(in_features=64, out_features=1, bias=True)\n)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch = 10\n",
    "#model = LSTMSeq2SeqOle(input_dim=num_features, out_seq_len=out_seq_len, hidden_dim=64)\n",
    "model = Models.LSTMSeq2SeqOle(input_dim=num_features, out_seq_len=out_seq_len, hidden_dim=64)\n",
    "#model = Models.LSTMSimple(input_dim=num_features, hidden_dim=64)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:52<00:00, 114.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.00624199\n",
      "epoch: 500 loss: 0.00012798\n",
      "epoch: 1000 loss: 0.03009448\n",
      "epoch: 1500 loss: 0.00054892\n",
      "epoch: 2000 loss: 0.03485906\n",
      "epoch: 2500 loss: 0.00072765\n",
      "epoch: 3000 loss: 0.00037811\n",
      "epoch: 3500 loss: 0.00021636\n",
      "epoch: 4000 loss: 0.00035702\n",
      "epoch: 4500 loss: 0.00012933\n",
      "epoch: 5000 loss: 0.00065895\n",
      "epoch: 5500 loss: 0.00016727\n",
      "epoch: 5999 loss: 0.0001295663\n"
     ]
    }
   ],
   "source": [
    "val_loss_hist = []\n",
    "last_val_scores = []\n",
    "max_val_scores = 4\n",
    "\n",
    "epochs = 6000\n",
    "for i in tqdm(range(epochs)):\n",
    "    # train\n",
    "    idx = np.random.choice(X.shape[0], mini_batch, replace=False)\n",
    "    optimizer.zero_grad()\n",
    "    #model.hidden_cell = (torch.zeros(2, mini_batch, model.hidden_layer_size).to(device),torch.zeros(2, mini_batch, model.hidden_layer_size).to(device))\n",
    "    y_pred = model(X[idx])\n",
    "    single_loss = loss(y_pred, y[idx])\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%500 == 0:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(DATA_PATH, \"model_param.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_data_scaled = scaler.transform(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def create_input_sequence(input_data, seq_len):\n",
    "    X = []\n",
    "    for i in range(len(input_data) - seq_len + 1):\n",
    "        train_seq = input_data[i:i + seq_len]\n",
    "        X.append(train_seq)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def batch_iterator(stop, desired_batch_size=100):\n",
    "    return [(batch * desired_batch_size, batch_size) for batch, batch_size\n",
    "            in enumerate(HelperFunction.batch_generator(stop, desired_batch_size))]\n",
    "\n",
    "#X_test = create_input_sequence(np.vstack((train_data_scaled[-seq_len:], test_data_scaled)), seq_len)\n",
    "#X_test = create_input_sequence(test_data_scaled[:-25], seq_len)\n",
    "#X_test = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "def predict_seq(model, input, desired_batch_size=100):\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for batch_start, batch_size in batch_iterator(len(input), desired_batch_size):\n",
    "            output = model(input[batch_start:batch_start+batch_size])\n",
    "            prediction.append(output.cpu().numpy())\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction.reshape(-1, prediction.shape[-1])\n",
    "\n",
    "def predict(model, input, seq_len,  desired_batch_size=100):\n",
    "    X = create_input_sequence(input, seq_len)\n",
    "    X = torch.FloatTensor(X).to(next(model.parameters()).device)\n",
    "    return predict_seq(model, X, desired_batch_size)\n",
    "\n",
    "prediction = predict(model, np.vstack((train_data_scaled[-seq_len:], test_data_scaled)), seq_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 574.90it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_len = 50#int(len(test_data) / out_seq_len) * out_seq_len\n",
    "test_inputs = np.vstack((train_data_scaled[-seq_len:].tolist(), test_data_scaled)).tolist()\n",
    "prediction = []\n",
    "for i in tqdm(range(0, pred_len, out_seq_len)):\n",
    "    seq = torch.FloatTensor([test_inputs[i+j:i+j+seq_len] for j in range(out_seq_len)]).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(seq)\n",
    "        prediction.append(output.cpu().numpy())\n",
    "\n",
    "prediction = np.array(prediction).reshape(-1, out_seq_len)\n",
    "#prediction_df = test_data[:prediction.shape[0]].assign(prediction=scaler_y.inverse_transform(prediction.reshape(-1, 1)).reshape(-1)).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "prediction_real = scaler_y.inverse_transform(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x19921fd20c8>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_o = 0 # offset into the future: 0 next hour, 1 predeciton of next hour +1\n",
    "last_test_data_index = min(len(test_data), f_o + prediction_real.shape[0])\n",
    "prediction_df = test_data[f_o: last_test_data_index].assign(prediction=prediction_real[0: last_test_data_index - f_o, f_o])\n",
    "\n",
    "plt.plot(prediction_df.index, prediction_df[\"value\"], label=\"value\")\n",
    "plt.plot(prediction_df.index, prediction_df[\"prediction\"], label=\"prediction\")\n",
    "plt.gcf().legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 102.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "          rmse       mape         mae\n0  1253.369965  11.645740  265.451539\n1  1265.156901  12.178234  275.090352\n2  1277.917527  12.065521  277.701935\n3  1293.128789  12.768168  289.293214\n4  1315.733933  12.448464  291.819003",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rmse</th>\n      <th>mape</th>\n      <th>mae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1253.369965</td>\n      <td>11.645740</td>\n      <td>265.451539</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1265.156901</td>\n      <td>12.178234</td>\n      <td>275.090352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1277.917527</td>\n      <td>12.065521</td>\n      <td>277.701935</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1293.128789</td>\n      <td>12.768168</td>\n      <td>289.293214</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1315.733933</td>\n      <td>12.448464</td>\n      <td>291.819003</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "for f_o in tqdm(range(prediction_real.shape[1])):\n",
    "    last_test_data_index = min(len(test_data), f_o + prediction_real.shape[0])\n",
    "    prediction_df = test_data[f_o: last_test_data_index].assign(prediction=prediction_real[0: last_test_data_index - f_o, f_o])\n",
    "    prediction_df.reset_index(inplace=True)\n",
    "    foobar = HelperFunction.TimeSeriesPlot(prediction_df, target_column, \"prediction\")\n",
    "    stats.append([foobar.rmse(), foobar.mape(), foobar.mae()])\n",
    "df_stats = pd.DataFrame(stats, columns=[\"rmse\", \"mape\", \"mae\"])\n",
    "df_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = df_stats.plot()\n",
    "#t.get_figure().savefig(\"../results/seq2seq_forecast_24h_book.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = np.loadtxt(os.path.join(DATA_PATH, \"predictions_inversed.csv\"))\n",
    "#np.savetxt(os.path.join(DATA_PATH, \"predictions_inversed.csv\"), prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#np.save(os.path.join(DATA_PATH, \"x_embedded\"), X_embedded)\n",
    "#sal = np.load(os.path.join(DATA_PATH, \"saliency_feature_ole.npy\"))\n",
    "X_embedded = np.load(os.path.join(DATA_PATH, \"x_embedded.npy\"))\n",
    "prediction = np.load(os.path.join(DATA_PATH, \"prediction_ole_numfeatures=1.npy\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.23it/s]\n"
     ]
    }
   ],
   "source": [
    "def sum_abs_diff_batch(a, b):\n",
    "    return np.sum(np.abs(a-b), 1)\n",
    "\n",
    "test_inputs = np.vstack((train_data_scaled[-seq_len:].tolist(), test_data_scaled)).tolist()\n",
    "mini_batch = 10\n",
    "batch_count = int(len(test_data) / mini_batch) * mini_batch\n",
    "prediction = np.empty((int(batch_count/mini_batch), mini_batch, seq_len))\n",
    "mask = torch.zeros(num_features).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, i in enumerate(tqdm(range(0, batch_count, mini_batch))):\n",
    "        seq = torch.FloatTensor([test_inputs[i+j:i+j+seq_len] for j in range(mini_batch)]).to(device)\n",
    "        pred = model(seq).cpu().numpy() # pred.shape = [batch, 24]\n",
    "        pred_ = np.empty((seq_len, mini_batch, out_seq_len))\n",
    "        for j in range(seq_len):\n",
    "            feature_vector_batch = seq[:, j].clone()\n",
    "            seq[:, j] = mask\n",
    "            pred_[j] = model(seq).cpu().numpy()\n",
    "            seq[:, j] = feature_vector_batch\n",
    "        prediction[batch] = np.array([sum_abs_diff_batch(pred, p) for p in pred_]).swapaxes(0, 1)\n",
    "\n",
    "sal = prediction.reshape(-1, seq_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% # saliancy per sample in seq\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "saliancy_per_sample() missing 1 required positional argument: 'seq_len'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-118-60d995a98751>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0msaliancy_per_sample_seq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdesired_batch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m \u001B[0msal2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msaliancy_per_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data_scaled\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mseq_len\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_data_scaled\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: saliancy_per_sample() missing 1 required positional argument: 'seq_len'"
     ]
    }
   ],
   "source": [
    "def sum_abs_diff_batch(a, b):\n",
    "    return np.sum(np.abs(a-b), 1)\n",
    "\n",
    "def saliancy_per_sample_seq(model, input, desired_batch_size=100):\n",
    "    \"\"\"\n",
    "    Computes the absolute difference between a prediction and a prediction where for each timestep the features where set\n",
    "    to zero for each sample\n",
    "    :param model: Some Pytorch.nn Model\n",
    "    :param input: Input must be of shape [samples, seq_len, features]\n",
    "    :param desired_batch_size:\n",
    "    :return: Returns a np.array of shape [samples, seq_len] where the second dimension is the absolut difference\n",
    "    between the original prediction and the prediction by setting that specific timestep to zero\n",
    "    \"\"\"\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        mask = torch.zeros(input.shape[2]).to(next(model.parameters()).device)\n",
    "        for batch, (batch_start, batch_size) in enumerate(batch_iterator(len(input), desired_batch_size)):\n",
    "            seq = input[batch_start: batch_start + batch_size]\n",
    "            pred = model(seq).cpu().numpy()\n",
    "            pred_ = np.empty((input.shape[1], batch_size, pred.shape[-1]))\n",
    "            for feature in range(input.shape[1]):\n",
    "                feature_vector_batch = seq[:, feature].clone()\n",
    "                seq[:, feature] = mask\n",
    "                pred_[feature] = model(seq).cpu().numpy()\n",
    "                seq[:, feature] = feature_vector_batch\n",
    "            prediction.append(np.array([sum_abs_diff_batch(pred, p) for p in pred_]).swapaxes(0, 1))\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction.reshape(-1, input.shape[1])\n",
    "\n",
    "def saliancy_per_sample(model, input, seq_len, desired_batch_size=100):\n",
    "    X = create_input_sequence(input, seq_len)\n",
    "    X = torch.FloatTensor(X).to(next(model.parameters()).device)\n",
    "    return saliancy_per_sample_seq(model, X, desired_batch_size)\n",
    "\n",
    "sal2 = saliancy_per_sample(model, np.vstack((train_data_scaled[-seq_len:], test_data_scaled)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "(51, 24, 1)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 24, 1)"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x19921a80588>]"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.mean(sal, axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def sum_abs_diff_batch(a, b):\n",
    "    return np.sum(np.abs(a-b), 1)\n",
    "\n",
    "def saliancy_per_feature_timestep(input, seq_len, out_seq_len, num_features, model, mini_batch=100):\n",
    "    batch_count = int((len(input) - seq_len) / mini_batch) * mini_batch\n",
    "    prediction = np.empty((int(batch_count / mini_batch), mini_batch, seq_len, num_features))\n",
    "    mask_mat = (torch.eye(num_features) - torch.ones(num_features)).abs().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, i in enumerate(tqdm(range(0, batch_count, mini_batch))):\n",
    "            seq = torch.FloatTensor([input[i+j:i+j+seq_len] for j in range(mini_batch)]).to(device)\n",
    "            pred = model(seq).cpu().numpy()\n",
    "            pred_ = np.empty((seq_len, num_features, mini_batch, out_seq_len))\n",
    "            for j in range(seq_len):\n",
    "                feature_vector_batch = seq[:, j].clone()\n",
    "                for k in range(num_features):\n",
    "                    seq[:, j] = feature_vector_batch * mask_mat[k]\n",
    "                    pred_[j, k] = model(seq).cpu().numpy()\n",
    "                    seq[:, j] = feature_vector_batch\n",
    "            prediction[batch] = np.array([[sum_abs_diff_batch(pred, f) for f in s] for s in pred_]).transpose((2, 0, 1))\n",
    "    return prediction.reshape(-1, seq_len, num_features)\n",
    "\n",
    "test_inputs = np.vstack((train_data_scaled[-seq_len:].tolist(), test_data_scaled)).tolist()\n",
    "sal = saliancy_per_feature_timestep(test_inputs, seq_len, out_seq_len, num_features, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% # saliancy per feature per sample in seq\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def saliancy_per_feature_seq(model, input, desired_batch_size=100):\n",
    "    \"\"\"\n",
    "    Computes the absolute difference between a prediction and a prediction where for each timestep each features is set\n",
    "    to zero for each sample\n",
    "    :param model: Some Pytorch.nn Model\n",
    "    :param input: Input must be of shape [samples, seq_len, features]\n",
    "    :param desired_batch_size:\n",
    "    :return: Returns a np.array of shape [samples, seq_len, num_features] where each value corresponds to setting\n",
    "    that feature of that sample to zero\n",
    "    \"\"\"\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        mask_mat = (torch.eye(input.shape[2]) - torch.ones(input.shape[2])).abs().to(next(model.parameters()).device)\n",
    "        for batch, (batch_start, batch_size) in enumerate(batch_iterator(len(input), desired_batch_size)):\n",
    "            seq = input[batch_start: batch_start + batch_size]\n",
    "            pred = model(seq).cpu().numpy()\n",
    "            pred_ = np.empty((input.shape[1], input.shape[2], batch_size, pred.shape[-1]))\n",
    "            for timestep in range(input.shape[1]):\n",
    "                feature_vector_batch = seq[:, timestep].clone()\n",
    "                for feature in range(input.shape[2]):\n",
    "                    seq[:, timestep] = feature_vector_batch * mask_mat[feature]\n",
    "                    pred_[timestep, feature] = model(seq).cpu().numpy()\n",
    "                    seq[:, timestep] = feature_vector_batch\n",
    "            prediction.append(np.array([[sum_abs_diff_batch(pred, f) for f in s] for s in pred_]).transpose((2, 0, 1)))\n",
    "    prediction = np.array(prediction)\n",
    "    return prediction.reshape(-1, input.shape[1], input.shape[2])\n",
    "\n",
    "def saliancy_per_feature(model, input, seq_len, desired_batch_size=100):\n",
    "    X = create_input_sequence(input, seq_len)\n",
    "    X = torch.FloatTensor(X).to(next(model.parameters()).device)\n",
    "    return saliancy_per_feature_seq(model, X, desired_batch_size)\n",
    "\n",
    "sal = saliancy_per_feature(model, np.vstack((train_data_scaled[-seq_len:], test_data_scaled)), seq_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x19923253548>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEWCAYAAAAgpUMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbrElEQVR4nO3de3Bc533e8ee3FywuBEBQhC4VSZGSacu0YssWLLtjV1FaW6GaWkxbsZYbd5RKLtWMNW2naaZqO2Nl5GmbxNMqyUSRJcts7ExixZHaBO7Qo8qOLXsaKyZp07pYlURRMglRpChxFySxC+zt1z/OWWAJLoAFid2zi/P9zGD23PHiYGeffc95z/uauwsAgHZLRF0AAEA8EUAAgEgQQACASBBAAIBIpKIuAADg/O3fv//iVCr1iKRr1LmViqqk58rl8meuu+66N2sLCSAA6GKpVOqRSy+99N2jo6PZRCLRkc2aq9WqnThxYtuxY8cekXRLbXmnpiUAoDnXjI6OnurU8JGkRCLho6OjkwpqaXPLIyoPAGBlJDo5fGrCMp6VOQQQAOCC7Ny5c/O6devet3Xr1vcsZz8CCABwQe644463xsfHX17ufgQQAOCC3HzzzWdGR0fLy92PVnAAsEr8xmM/2fjSsdP9K3nMd146mP/Cre87spLHrKEGBACIBDUgAFglWlVTaRVqQACASBBAAIAL8olPfGLLRz/60atfffXVzCWXXPLe+++/f30z+3EJDgBwQb7xjW+8ej77UQMCAESCAAIARIIAAgBEggACgO5WrVarFnUhlhKWsVq/jAACgO723IkTJ4Y7OYTC8YCGJT1Xv5xWcADQxcrl8meOHTv2yLFjx7piRNT6hebe8cNIAABWoU5NSwDAKkcAAQAiQQABACJBAAEAIkEAAQAiQQABACJBAAEAIkEAAQAiQQABACJBAAEAIkEAAQAi0XGdka5fv943b94cdTEAoKvs37//LXcfjbocy9FxAbR582bt27cv6mIAQFcxs59FXYbl4hIcACASBBAAIBIEEAAgEgQQACASBBAAIBIEEAAgEgQQACASBBAAdIDH90/oaz88HHUx2ooAAoAO8Nj+CT2+fyLqYrQVAQQAHSBXKGltf0/UxWgrAggAOkAuX9Ta/nTUxWgrAggAOkAuX9IIAQQAaKfpUkWFUoVLcACA9srlS5LEJTgAQHvlCkVJ0gg1IABAO2WnwhpQHzUgAEAb5fJBDYh7QACAtsoVghrQyAA1IABAG2VrNaA+akAAgDbK5UvKpBLq60lGXZS2IoAAIGK5fDF2LeAkAggAIpfNl2L3DJBEAAFA5OLYD5xEAAFA5HL5UuwaIEgEEABELpsvxa4JttRkAJnZdjN70cwOmtk9Ddb/WzP7qZk9Y2bfNrMr6tbdbmYvhz+3r2ThAaDbubsmC8XYPYQqNRFAZpaU9ICkmyVtk/QpM9s2b7MfSxpz9/dKekzS74T7rpN0r6QPSbpe0r1mNrJyxQeA7jZVrKhU8dh1wyM1VwO6XtJBdz/k7kVJj0raUb+Bu3/H3fPh7NOSNoTTvyjpSXc/6e5ZSU9K2r4yRQeA7pedimdHpFJzAXS5pCN18xPhsoXcKemb57kvAMTKZCGeQzFIUqqJbazBMm+4odmnJY1J+vnl7GtmuyTtkqRNmzY1USQAWB2yMe2IVGquBjQhaWPd/AZJR+dvZGYfk/SfJN3i7jPL2dfdH3b3MXcfGx0dbbbsAND1suFgdHEbjltqLoD2StpqZlvMrEfSbZLG6zcws/dLekhB+LxZt+oJSTeZ2UjY+OCmcBkAQNJkjGtAS16Cc/eymd2tIDiSkna7+/Nmdp+kfe4+LukLktZI+nMzk6TD7n6Lu580s88rCDFJus/dT7bkLwGALlSrAQ3HsBVcM/eA5O57JO2Zt+xzddMfW2Tf3ZJ2n28BAWA1y+aLWpNJqScVv34B4vcXA0AHmcyXYln7kQggAIhUNl+MZTc8EgEEAJHKFUqxfAhVIoAAIFI5LsEBAKKQjeloqBIBBACRqVZdk4VSLB9ClQggAIjMqemS3KVhakAAgHaKczc8EgEEAJHJ5eM7FINEAAFAZHK1bnioAQEA2ilLDQgAEIVaDSiOw3FLBBAARCaXL8pMGiKAAADtlA17QUgmGg0evfoRQAAQkVyhFNvLbxIBBACRyeWLsRwJtYYAAoCI5PLx7YZHIoAAIDJZakAAgCjk8iWtpQYEAGinUqWqMzPl2D6EKhFAABCJ2YdQqQEBANqp1hEp94AAAG2VK8S7Gx6JAAKASGSn4t0RqUQAAUAkuAdEAAFAJHKF2j0gAggA0EbZfEmphGlNJhV1USJDAAFABIKHUHtkFs+esCUCCAAiEXREGt/LbxIBBACRyOaLse6IVCKAACAStUtwcUYAAUAEcvl4D0YnEUAAEIlsvqiRAWpAAIA2mi5VNFOuapgaEACgnbJ5uuGRCCAAaLvsVNAND63gmmBm283sRTM7aGb3NFh/g5n9yMzKZnbrvHUVMzsQ/oyvVMEBoFvVuuEZjnkALdkHhJklJT0g6eOSJiTtNbNxd/9p3WaHJf2qpH/X4BAFd792BcoKAKtCrSPSuF+Ca6YTouslHXT3Q5JkZo9K2iFpNoDc/bVwXbUFZQSAVYV7QIFmLsFdLulI3fxEuKxZvWa2z8yeNrNfbrSBme0Kt9l34sSJZRwaALoPQzEEmgmgRj3l+TJ+xyZ3H5P0TyX9rplddc7B3B929zF3HxsdHV3GoQGg++TyRfWmE+pNJ6MuSqSaCaAJSRvr5jdIOtrsL3D3o+HrIUnflfT+ZZQPAFadXL4U+8tvUnMBtFfSVjPbYmY9km6T1FRrNjMbMbNMOL1e0kdUd+8IAOIomy/F/iFUqYkAcveypLslPSHpBUlfd/fnzew+M7tFkszsg2Y2IWmnpIfM7Plw93dL2mdmP5H0HUm/Na/1HADETi5fpAak5lrByd33SNozb9nn6qb3Krg0N3+/v5b0cxdYRgBYVXKFkrZevCbqYkSOnhAAoM2CweioARFAANBG7h42QuAeEAEEAG10ZqasctVj/wyQRAABQFvNPYTKJTgCCADaiG545hBAANBGdMMzhwACgDaaqwERQAQQALTRZIF7QDUEEAC0UW00VLriIYAAoK2y+aIGMymlk3z8cgYAoI0mC6XYD8VdQwABQBtl6Yh0FgEEAG2UzZdogh0igACgjSbpiHQWAQQAbZSlI9JZBBAAtEml6jo1XaIGFCKAAKBNThVKcpfW8gyQJAIIANpmthueAQJIIoAAoG2yDMVwFgIIANpkshDUgLgEFyCAAKBNav3A8SBqgAACgDbJFRgLqB4BBABtkssXlTBpqJcAkgggAGibbL6o4b60EgmLuigdgQACgDbJ5XkItR4BBABtkqMj0rMQQADQJgzFcDYCCADaJJcv8QxQHQIIANokx1AMZyGAAKANiuWqpooVhmKoQwABQBvkat3wEECzCCAAaIMcHZGegwACgDaYCyBqQDUEEAC0wexYQNSAZhFAANAGuTz3gOZrKoDMbLuZvWhmB83sngbrbzCzH5lZ2cxunbfudjN7Ofy5faUKDgDdhHtA51oygMwsKekBSTdL2ibpU2a2bd5mhyX9qqQ/nbfvOkn3SvqQpOsl3WtmIxdebADoLtl8SemkaaAnGXVROkYzNaDrJR1090PuXpT0qKQd9Ru4+2vu/oyk6rx9f1HSk+5+0t2zkp6UtH0Fyg0AXaX2EKoZPWHXNBNAl0s6Ujc/ES5rxoXsCwCrBt3wnKuZAGoU197k8Zva18x2mdk+M9t34sSJJg8NAN2DjkjP1UwATUjaWDe/QdLRJo/f1L7u/rC7j7n72OjoaJOHBoDuwVAM52omgPZK2mpmW8ysR9JtksabPP4Tkm4ys5Gw8cFN4TIAiJVcoUgAzbNkALl7WdLdCoLjBUlfd/fnzew+M7tFkszsg2Y2IWmnpIfM7Plw35OSPq8gxPZKui9cBgCx4e7K5ktcgpsn1cxG7r5H0p55yz5XN71XweW1RvvulrT7AsoIAF2tUKqoWK7yDNA89IQAAC1GP3CNEUAA0GJz/cARQPUIIABoscmwBjTcxyW4egQQALRYNgygkQFqQPUIIABoMYZiaIwAAoAWmyzULsFRA6pHAAFAi2WniupLJ9WbpifsegQQALRY8BAqtZ/5CCAAaLHJQlHD3P85BwEEAC1GDagxAggAWoyhGBojgACgxSbzJQ1TAzoHAQQALeTuyhW4BNcIAQQALXR6pqxK1bWWbnjOQQABQAvlpugJeyEEEAC0EN3wLIwAAoAWyhWoAS2EAAKAFsqFNSBGQz0XAQQALZSdYjC6hRBAANBCOXrCXhABBAAtlMuXNNibUirJx+18nBEAaCG64VkYAQQALZTLl2gBtwACCABaKJcv0gJuAQQQALRQNl/SWhogNEQAAUAL5fJFmmAvgAACgBYpV6o6NV3mEtwCCCAAaJFT02VJdMOzEAIIAFqEjkgXRwABQIvM9QNHDagRAggAWiSXr/WETQ2oEQIIAFokGwYQreAaI4AAoEUYimFxBBAAtEguX1LCpMFMKuqidCQCCABaJBt2w5NIWNRF6UhNBZCZbTezF83soJnd02B9xsz+LFz/N2a2OVy+2cwKZnYg/PniyhYfADpXjm54FrVkvdDMkpIekPRxSROS9prZuLv/tG6zOyVl3f0dZnabpN+W9Mlw3Svufu0KlxsAOl6uUKQJ9iKaqQFdL+mgux9y96KkRyXtmLfNDklfCacfk/T3zIw6J4BYy06VeAh1Ec0E0OWSjtTNT4TLGm7j7mVJk5IuCtdtMbMfm9lTZvZ3LrC8ANA1JgslDVMDWlAzTTMa1WS8yW3ekLTJ3d82s+sk/YWZvcfdT521s9kuSbskadOmTU0UCQA6H6OhLq6ZGtCEpI118xskHV1oGzNLSRqWdNLdZ9z9bUly9/2SXpH0zvm/wN0fdvcxdx8bHR1d/l8BAB1mplxRvljhIdRFNBNAeyVtNbMtZtYj6TZJ4/O2GZd0ezh9q6S/cnc3s9GwEYPM7EpJWyUdWpmiA0Dnmgx7QRimBrSgJS/BuXvZzO6W9ISkpKTd7v68md0naZ+7j0v6sqQ/NrODkk4qCClJukHSfWZWllSR9C/d/WQr/hAA6CR0w7O0ph7Pdfc9kvbMW/a5uulpSTsb7Pe4pMcvsIwA0HUYimFp9IQAAC1Q6wl7mAdRF0QAAUAL1DoiHRmgBrQQAggAWqB2D4iueBZGAAFAC+QKRfUkE+rvSUZdlI5FAAFAC+SmSlrbnxa9ki2MAAKAFqAj0qURQACwgOlSRQ899YrePD297H2z+RIjoS6BAAKABXzth4f1X7/5//SZr+xToVhZ1r65fJGHUJdAAAFAA6VKVV/63iFtGOnTs69P6jce+4nc5/fDvLBgMDpqQIshgACggb88cFRHJ6f1+R3X6N9vv1r/+5k39PvfPtjUvu4eBNAANaDFNNUVDwDESbXq+uJTr+jqSwd147tGdeO7RvXy8TO6/1sv6R0Xr9EvvfeyRffPFysqVqp0w7MEakAAMM+3Xjiug2+e0a/deJXMTGam//KPrtHYFSP69T8/oGcnJhfdP1fgIdRmEEAAUMfd9YfffUWb1vXrl35urqaTSSX1xX92nS4ayOgzX92r46cWbhmXnQq64aEV3OIIIACo8/ShkzpwJKddN1ypVPLsj8j1azJ65PYxnZku6198deGWcbWOSHkOaHEEEADU+cPvHtT6NRndet2GhuvffdmQfu+29y/aMi5XYCiGZhBAABB67vVJff/lt3TnR7eoN71wH24f23bJoi3jGIyuObSCA4DQg999RYOZlH7lw5uW3PauG65csGVcLrwHNEwALYoaEABIevWtKe157g19+m9foaHepYNjsZZxuUJJ/T1JZVL0hL0YAggAJD301CtKJxO64yNbmt5noZZx2XyR+z9NIIAAxN6xyWk9/qMJ/ZOxDRodzCxr30Yt4ybzJYbibgIBBCD2dv/fV1V16a4brjqv/ee3jDuZL2qEbniWRAABiLXJfEl/8vTP9A/ee5k2rus/7+PUt4z78eEcD6E2gQACEGtf/cFrmipW9Gs3nl/tp95dN1ypf/yB4PkhuuFZGs2wAcRWoVjR//jr1/R3r75YV186dMHHq7WMS5h003suXYESrm4EEIDY+rO9h3VyqrgitZ+aTCqpL+x834odbzXjEhyAWCpVqvrS91/VBzeP6IOb10VdnFgigADE0viBo3o9V1jR2g+WhwACEDvVquvBcMC5X3jXxVEXJ7YIIACxM3/AOUSDAAIQK7UB5zau6ztrwDm0HwEEIFbmBpy76pwB59BenH0AsfLgU69o/Zoe7VxgwDm0DwEEIDaee31S33vphO5YYsA5tAcPogLnwd01Vazo9HRJp6fLOj1dVqFYUb5YVqFUCacrKpTCZcWqCqVysCxcXihWVHGXu+RzB56dDpYH62vzkpROmjLppPrCn950Qn09SfWmg5/ZZem5ZYO9KV0y1KtLhno10p/u2hvvZ2bKemYipwNHcspOFbVuIKOLBnp00ZoerRvo0fo1Ga0b6FF/T7Lh3/jgU8GAc5/+8BURlB7zEUCIpXKlqtPTZU0WSjo1XdKpQv108FoLltPTJZ2qny6UdGamrKov/XskKZkw9aeT6u1Jqr8nDI7wNZkIPiTNTLWPSzPVTQfL5z5LTeVqVYViRbl8UcdKVRVKFU2XKrOvpcriBetJJjQ6mNGlw726ZCijiwd7w3DKzL5ePNSrwUwq0qCqVF0vHT+tA0dyOnA4CJ2X3zw9e94zqYRmytWG+/amE7poIDMbTBcNZDTcl9Y3n31Dd/38VU0NOIfWI4DQlYrl6mztYy4sgiA5NRsYc/OThTBYCsG6MzPlRY+fTJgGe1PBTyatwd6ULl/bp6HeQQ32pjTUlw7XB69rMikNZFKz4dLfk1R/OqXenoR6kom2fpCXK1VNl4OQmg5DabJQ0punZ3T81LSOn5rRm6emdezUtF48dlrff+ktnW5wPnrTidm/b7A3rcFMavZvnVueml2/Jlzf15NUb6pW+0qoN51UJrX0OTg2Oa0DR7L6cRg4z74+qXyxIkla25/W+zas1fZrLtW1m9bq2g1rNTLQo3yxrLfPFPX2VFEnp2bqpot668yMTk4V9faZol4+fkZvnZnRUF9a//wjm1tx2nEemgogM9su6fckJSU94u6/NW99RtJXJV0n6W1Jn3T318J1/0HSnZIqkv6Vuz+xYqVHV6hWXdPliqbrvq3nZyo6M1NWvlgOXyuamilraqaiqWJZU+GyuW3qL3eVNF1q/M23Xu0Dc6gvreG+tDau69dwX1pDvcH8UF9qdr62zVBfSkO96QUv4XSDVDKhNcmE1mSa/345NVOuC6jg58TpmeB8z8zV/o6fmp6dngrDoVmZVOKsUApCKqFMKqnDJ/M6Fo4mmk6atl02pJ3XbQjCZuOINl/U3/D/0d+TUv+6VFPDKHh4uTOR6M7/62q05DvUzJKSHpD0cUkTkvaa2bi7/7RuszslZd39HWZ2m6TflvRJM9sm6TZJ75H0tyR9y8ze6e7Le+fGkNfdG6i6qxrOV6rBdLU6t7x2H6Hqrkp1brtytapy1VWu+Nz87HTj+WK5qmLFVSpXVaoEP7PLKnPLZspVlSquYl2wzJSC6elyZe7bdznYfzl60wkN9AQ1iv6epNZkgqDYMNKnofDb9lBd7WOo7lv6UN/ct/EkHzRNG8iktCWT0pb1A03vU6m6zswEYXQmDKkz0+XZLxnTpWr4HqibPmdd8Hr9lnW6duNaXbtprbZdNtSSBgJmpi79TrFqNfMV6XpJB939kCSZ2aOSdkiqD6Adkn4znH5M0h9Y8HVlh6RH3X1G0qtmdjA83g9Wpvhzcvmibv3iD+Thndq5m7qqu6l79rraTd7Z6bpL5/Xbzt4Err8hPLt8Lig8vIEcHKvudzVYX63dbA7LUPWz13eanmRCPamE0klTOplQOpzvSSaCb7HppNb298x+u63dAM+kE+pNJcPLMonZm+IDmZQGesLXTEoDmWC6P53k2YwukUyYhsOaI3A+mgmgyyUdqZufkPShhbZx97KZTUq6KFz+9Lx9L5//C8xsl6RdkrRp06Zmy36WZML0rksGwwOe9XLODd6F1smk2tzZN4LnLa/bobZdbZu5+bmvWvPXJRLh0cLlCWu8v9WtTyRMCQumkwmTNZq2YBszKZU0JRMJpROmZMIWnE+F06lEMF8LmUwyqXQqCJtU+DsAYCU1E0CNPnnmf0dfaJtm9pW7PyzpYUkaGxs7r+//g71pPfArHzifXQEAEWjmWseEpI118xskHV1oGzNLSRqWdLLJfQEAMdRMAO2VtNXMtphZj4JGBePzthmXdHs4faukv/LgJsi4pNvMLGNmWyRtlfTDlSk6AKCbLXkJLrync7ekJxQ0w97t7s+b2X2S9rn7uKQvS/rjsJHBSQUhpXC7rytosFCW9FlawAEAJMm8w5pcjY2N+b59+6IuBgB0FTPb7+5jUZdjOWjvCgCIBAEEAIgEAQQAiAQBBACIRMc1QjCzE5J+dgGHWC/prRUqTjfjPAQ4DwHOQ2A1n4cr3H006kIsR8cF0IUys33d1hKkFTgPAc5DgPMQ4Dx0Fi7BAQAiQQABACKxGgPo4agL0CE4DwHOQ4DzEOA8dJBVdw8IANAdVmMNCADQBVZNAJnZdjN70cwOmtk9UZcnKmb2mpk9a2YHzCxWneqZ2W4ze9PMnqtbts7MnjSzl8PXkSjL2A4LnIffNLPXw/fFATP7+1GWsR3MbKOZfcfMXjCz583sX4fLY/ee6FSrIoDMLCnpAUk3S9om6VNmti3aUkXqF9z92hg2N/0jSdvnLbtH0rfdfaukb4fzq90f6dzzIEn3h++La919T5vLFIWypF9393dL+rCkz4afC3F8T3SkVRFAkq6XdNDdD7l7UdKjknZEXCa0mbt/T8FwIPV2SPpKOP0VSb/c1kJFYIHzEDvu/oa7/yicPi3pBUmXK4bviU61WgLocklH6uYnwmVx5JL+j5ntN7NdURemA1zi7m9IwQeSpIsjLk+U7jazZ8JLdLG67GRmmyW9X9LfiPdEx1gtAWQNlsW1ed9H3P0DCi5HftbMboi6QOgID0q6StK1kt6Q9N+iLU77mNkaSY9L+jfufirq8mDOagmgCUkb6+Y3SDoaUVki5e5Hw9c3Jf0vBZcn4+y4mV0mSeHrmxGXJxLuftzdK+5elfQlxeR9YWZpBeHzJ+7+P8PFvCc6xGoJoL2StprZFjPrUTAk+HjEZWo7Mxsws8HatKSbJD23+F6r3rik28Pp2yX9ZYRliUztAzf0DxWD94WZmaQvS3rB3f973SreEx1i1TyIGjYr/V1JSUm73f0/R1yktjOzKxXUeiQpJelP43QezOxrkm5U0OPxcUn3SvoLSV+XtEnSYUk73X1V36Bf4DzcqODym0t6TdJdtfsgq5WZfVTS9yU9K6kaLv6PCu4Dxeo90alWTQABALrLarkEBwDoMgQQACASBBAAIBIEEAAgEgQQACASBBAAIBIEEAAgEgQQACAS/x906R8XMvb97AAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, num_features):\n",
    "    plt.plot(np.mean(sal[:,:,i], axis=0), label=i+1)\n",
    "\n",
    "plt.gcf().legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_inputs, _ = create_input_output_sequence(np.vstack((train_data_scaled[-seq_len:].tolist(), test_data_scaled)), seq_len, out_seq_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mini_batch = 100\n",
    "batch_count = int(test_inputs.shape[0] / mini_batch) * mini_batch\n",
    "lstm = model.lstm_in\n",
    "\n",
    "states = []\n",
    "with torch.no_grad():\n",
    "    for batch, i in enumerate(tqdm(range(0, batch_count, mini_batch))):\n",
    "        _, (h, _) = lstm(test_inputs[i:i+mini_batch])\n",
    "        states.append(h[-1].cpu().numpy()) # h[-1] last layer\n",
    "states = np.array(states).reshape(-1, model.hidden_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, verbose=1, n_jobs=-1, perplexity=10).fit_transform(states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=prediction[:X_embedded.shape[0], 0], s=1)\n",
    "plt.viridis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = np.ones(48)\n",
    "weights[-1] = 48\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=np.average(test_inputs[:X_embedded.shape[0]].reshape(-1, 48), axis=1, weights=weights), s=1)\n",
    "plt.viridis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = np.ones(48)\n",
    "weights[-1] = 48\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=np.average(test_inputs[:X_embedded.shape[0]].reshape(-1, 48), axis=1, weights=weights), s=1)\n",
    "plt.viridis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}